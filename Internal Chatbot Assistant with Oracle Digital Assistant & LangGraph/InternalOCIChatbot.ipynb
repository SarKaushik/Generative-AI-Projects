{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f315a09-6050-4410-bc9a-7bc54f5e96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install oci python-docx PyPDF2 openai langgraph langchain langchain-openai\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabca5d-01b2-47fb-9fe3-e25ce1d8cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install oci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca6c07e-812f-4e63-97da-34cda2c82435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Read files from OCI Object Storage into Python\n",
    "\n",
    "from io import BytesIO\n",
    "from docx import Document   # for reading .docx files\n",
    "from PyPDF2 import PdfReader  # for reading .pdf files\n",
    "import oci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2595151e-db7a-4e8c-a2a1-8e46335b21f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_path = r\"A:\\AI Projects\\oci\\config.ini\"  # raw string avoids issues with backslashes\n",
    "config = oci.config.from_file(file_location=config_path, profile_name=\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4316b9f0-aee5-4d36-bd8e-2a6c4860cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Object Storage client\n",
    "object_storage_client = oci.ject_storage.ObjectStorageClient(config)ob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "625a8e80-0f7b-4824-8923-d423691c218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get namespace\n",
    "namespace = object_storage_client.get_namespace().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7837a2a6-330c-4bb7-a566-18f1b1d93959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to OCI successfully!\n",
      "Namespace: axrmgaiopsw4\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Connected to OCI successfully!\")\n",
    "print(\"Namespace:\", namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3513276c-890a-4172-8609-06d37a622d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in bucket:\n",
      "Prokngb.docx\n"
     ]
    }
   ],
   "source": [
    "bucket_name = \"policy-docs-bucket\"\n",
    "# List all objects in the bucket\n",
    "response = object_storage_client.list_objects(namespace, bucket_name)\n",
    "print(\"Files in bucket:\")\n",
    "for obj in response.data.objects:\n",
    "    print(obj.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e922f70-1a79-4a9a-b269-a5c69a4463fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read documents from OCI \n",
    "def read_docx_from_oci(object_name):\n",
    "    response = object_storage_client.get_object(namespace, bucket_name, object_name)\n",
    "    file_stream = BytesIO(response.data.content)\n",
    "    doc = Document(file_stream)\n",
    "    return \"\\n\".join([p.text for p in doc.paragraphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c31c9d3-473d-45dd-bb24-52aeee885ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1 documents from Object Storage\n"
     ]
    }
   ],
   "source": [
    "# Load all documents into a Python list\n",
    "docs = []\n",
    "\n",
    "for obj in response.data.objects:\n",
    "    if obj.name.endswith(\".docx\"):\n",
    "        text = read_docx_from_oci(obj.name)\n",
    "        docs.append({\"filename\": obj.name, \"text\": text})\n",
    "    elif obj.name.endswith(\".pdf\"):\n",
    "        text = read_pdf_from_oci(obj.name)\n",
    "        docs.append({\"filename\": obj.name, \"text\": text})\n",
    "\n",
    "print(f\"✅ Loaded {len(docs)} documents from Object Storage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce11748-8b88-4ab4-b49c-217422e5f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "## Genrate Embeddings using OpenAI\n",
    "client  = OpenAI(api_key=\"your_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a761a839-e085-40ce-97ee-b4c91c47ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text):\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Example: generate embeddings for all documents\n",
    "for doc in docs:\n",
    "    doc['embedding'] = embed_text(doc['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4217cb4a-27eb-4c29-9e0c-7056bfb912ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7e0d2-96b3-4c71-b96e-2053c046ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM + Embeddings\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=\"YOUR_API_KEY\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=\"YOUR_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeea3ba-255b-4026-b60c-3af4a0754ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu\n",
    "# Build FAISS vector store from docs\n",
    "texts = [doc[\"text\"] for doc in docs]\n",
    "metadatas = [{\"source\": doc[\"filename\"]} for doc in docs]\n",
    "\n",
    "vectorstore = FAISS.from_texts(texts, embeddings, metadatas=metadatas)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "525cdf01-7e4a-48eb-b15b-902a110ad57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    context: str\n",
    "    answer: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcc793d8-a029-40db-8168-c3e2c36076fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Node 1: Retrieve relevant docs\n",
    "def retrieve_node(state: AgentState):\n",
    "    docs = retriever.get_relevant_documents(state[\"question\"])\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    return {\"context\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bc1fe32-b839-4699-87d2-456a150169f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 2: Generate answer\n",
    "def answer_node(state: AgentState):\n",
    "    messages = [\n",
    "        HumanMessage(content=f\"Answer the question based on the context.\\n\\nContext:\\n{state['context']}\\n\\nQuestion: {state['question']}\")\n",
    "    ]\n",
    "    response = llm(messages)\n",
    "    return {\"answer\": response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b719c150-8a50-45a3-bde5-abd63b534f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Build LangGraph workflow\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"answer\", answer_node)\n",
    "\n",
    "graph.set_entry_point(\"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"answer\")\n",
    "graph.add_edge(\"answer\", END)\n",
    "\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4a1bb9b-ebb6-450d-9194-4ef0ce5fa5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "query = \"Give me basic about Oracle R12 Procurement process?\"\n",
    "state = {\"question\": query, \"context\": \"\", \"answer\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f38d4d0f-ad64-47cb-ab96-1ddea9d10468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarve\\AppData\\Local\\Temp\\ipykernel_35872\\2454362818.py:4: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(state[\"question\"])\n",
      "C:\\Users\\sarve\\AppData\\Local\\Temp\\ipykernel_35872\\2964837565.py:6: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(messages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Give me basic about Oracle R12 Procurement process?\n",
      "A: The Oracle R12 Procurement process is designed to streamline and automate the procure-to-pay cycle, enabling organizations to efficiently manage their purchasing activities. Here are the basic components of the process:\n",
      "\n",
      "1. **Requisitioning**: Employees create purchase requisitions using the iProcurement module, which provides a user-friendly interface for selecting items and services.\n",
      "\n",
      "2. **Approval Workflows**: Requisitions are routed through automated approval workflows based on predefined purchasing policies, approval hierarchies, and spending limits.\n",
      "\n",
      "3. **Sourcing**: The Oracle Sourcing module facilitates competitive bidding and supplier negotiations to secure the best terms and prices for goods and services.\n",
      "\n",
      "4. **Purchasing**: Once requisitions are approved, Oracle Purchasing handles the core buying activities, generating purchase orders that are sent to suppliers.\n",
      "\n",
      "5. **Supplier Management**: The Supplier Lifecycle Management module tracks supplier onboarding, performance, and risk, ensuring that organizations work with reliable vendors.\n",
      "\n",
      "6. **Contract Management**: Procurement Contracts ensure that terms and conditions are standardized and enforceable, helping to maintain compliance and control over purchasing agreements.\n",
      "\n",
      "7. **Receiving and Invoicing**: Upon receipt of goods or services, organizations can verify deliveries and process invoices, ensuring that payments are made accurately and on time.\n",
      "\n",
      "8. **Analytics and Reporting**: Real-time dashboards and analytics provide visibility into procurement metrics, such as spend by category and supplier performance, enabling data-driven decision-making.\n",
      "\n",
      "Overall, Oracle R12 Procurement integrates these components into a cohesive system that enhances operational efficiency, compliance, and cost control across the organization.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(state)\n",
    "print(\"Q:\", query)\n",
    "print(\"A:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae190de-1b2e-4202-ab00-58edd385cf81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
